{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833b7a68",
   "metadata": {},
   "source": [
    "### Notebook Overview:\n",
    "* The following notebook is a condensed version demonstrating the core functionality of the VAE and GA modules. This notebook trains 1 VAE model and deploys the resultant low-dimensional representation into a genetic algorithm optimisation framework to maximise the compactness metric.\n",
    "* For a complete functionality, we reccomend cloning the GitHub repo and running the examples inside ```/examples/vae_examples/``` and ```/examples/ga_examples/```\n",
    "\n",
    "### Core Packages:\n",
    "\n",
    "* ```vae``` - https://github.com/jhell1717/latentoptim/tree/main/vae : For building and training the VAE models.\n",
    "* ```data``` - https://github.com/jhell1717/latentoptim/tree/main/data : For creating geometric shape training data.\n",
    "* ```utils``` - https://github.com/jhell1717/latentoptim/tree/main/utils : Supporting functionality (e.g, visualising latent distributions & generated \n",
    "shapes.)\n",
    "\n",
    "* ```pyga``` - https://github.com/mark-hobbs/pyga : Abstracted genetic algorithm for easy integration with numerical optimisation objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660cf89",
   "metadata": {},
   "source": [
    "### Import Repo and Install packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d63aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/jhell1717/latentoptim.git\n",
    "!pip install git+https://github.com/jhell1717/latentoptim.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94d958",
   "metadata": {},
   "source": [
    "### Imports\n",
    "* Import standard packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb330c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Our custom packages.\n",
    "import pyga\n",
    "import vae\n",
    "import data\n",
    "import utils\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b32dda",
   "metadata": {},
   "source": [
    "### Generate Random Shape Dataset:\n",
    "* User specifies resolution with ```resolution``` variable in ```Generator()``` class.\n",
    "* User specifies number of shapes to generate with ```num_shapes``` in ```Generator()``` class.\n",
    "* ```Generator``` class is used to create random shape objects.\n",
    "* Generated shapes will be stored as a .pkl file here: ```/content/latentoptim/examples/vae_examples/colab/demo_shapes.pkl```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'/Users/joshuahellewell/Desktop/01-dev/latentoptim/examples/vae_examples/colab'\n",
    "# Creates shape random shape data.\n",
    "shape_data = data.Generator(resolution=200,num_shapes=10000).generate_shapes()\n",
    "\n",
    "file_path = os.path.join(base_dir,'demo_shapes.pkl'),\n",
    "\n",
    "# Save shape population as .pkl\n",
    "with open(file_path[0], \"wb\") as f:\n",
    "    pickle.dump(shape_data, f)\n",
    "\n",
    "dataset = vae.ShapeData(shape_data) # Create dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39412a95",
   "metadata": {},
   "source": [
    "### Visualise a random generated shape from the dataset:\n",
    "* Random shapes are sampled from the generated population.\n",
    "* All shapes are examples from the defined categories specified in the ```Generator``` class.\n",
    "\n",
    "***Shape Representation***\n",
    "* The shapes are represented as a series of nodes on an x,y plane.\n",
    "* High resolution shape representations might include, 200+ nodes.\n",
    "* To optimise shapes in this representation, we require adjusting all 200 nodes to change the resultant geometry.\n",
    "* In realising a low-dimensional representation, defined as the latent representation, we can reduce the dimensionality of the design space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_shape_id = np.random.choice(range(0,len(dataset.shapes))) # Select random test index.\n",
    "dataset.shapes[random_shape_id].plot() # Visualise shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1efb1",
   "metadata": {},
   "source": [
    "### Build VAE Model:\n",
    "* User specifies ```input_size```. e.g., 200 nodes x,y = 200*2\n",
    "* User specifies dimension of latent space with ```latent_dim``` variable.\n",
    "* ```VAE``` class is used to build the VAE architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimensions = 3\n",
    "number_nodes = 200 \n",
    "model = vae.VAE(input_size=number_nodes*2,latent_dim=latent_dimensions) # Create model object\n",
    "model.to(device) # Assign model to GPU if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b75eed",
   "metadata": {},
   "source": [
    "### Train VAE Model:\n",
    "* Train the VAE model defined as ```model``` above.\n",
    "* User specifies epochs, batch size and frequency of training checkpoints.\n",
    "* Change the ```model_name``` variable to denote a new model.\n",
    "* The model will be saved and the loss plot stored in ```/content/latentoptim/examples/vae_examples/colab/example_model```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "trainer = vae.Trainer(dataset, model, base_dir=base_dir,\n",
    "                      trained_data=os.path.join(base_dir,'demo_shapes.pkl'), model_name='example_model2', batch_size=batch_size,lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "trainer.train_model(epochs=50,checkpoint_interval=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a7273",
   "metadata": {},
   "source": [
    "### Specify Model Details\n",
    "* In this example, we test only 1 model. \n",
    "* For additional models, we can add additional models into the array ```models``` and specify their corresponding latent dimensions in ```latent_dims```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model.to('cpu')] # List of trained models to sample and generate designs.\n",
    "latent_dims = [latent_dimensions] # List of dimensions associated with each latent model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d599e",
   "metadata": {},
   "source": [
    "### Sample Trained VAE Model:\n",
    "* For each combination of the latent variables (if > 1), we generate the latent space for shapes samples between latent values $[-3,+3]$\n",
    "* Each 2D visualisation of latent dimension pairings are stored here: ```/content/latent_space_plots```\n",
    "* We fix all but the visualised latent dimensions to values of $0.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d589821",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_all_latent_combinations(models,latent_dims,vae_metrics=vae.Metrics,shapes_path=os.path.join(base_dir,'demo_shapes.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dbfe97",
   "metadata": {},
   "source": [
    "### Genetic Algorithm Optimisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf336b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.ShapeVAE.set_model(model) # Set trained model to model in GPR workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b81aefb",
   "metadata": {},
   "source": [
    "### Using Original Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = random.sample(range(len(dataset.shapes)), 200)\n",
    "random_subset = [utils.ShapeVAE(dataset.shapes[i].points.flatten(),model) for i in random_indexes]\n",
    "sh = [torch.tensor(shape.genes, dtype = torch.float32).view(-1) for shape in random_subset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced5acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 20 # GA initial population size. \n",
    "\n",
    "individuals = [utils.ShapeVAE(np.random.uniform(-3, 3, size=3)) for _ in range(population_size)] # Sample from random distribution.\n",
    "\n",
    "population = pyga.Population(individuals) # Create population with generated individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f766fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.plot() # View samples of initial population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93e552",
   "metadata": {},
   "source": [
    "### Genetic Algorithm Settings:\n",
    "* ```num_generations``` - Specifies how many evolutions of the GA to run.\n",
    "* ```num_parents``` - At each evolution, how many individuals to consider for crossover & mutation.\n",
    "* ```mutation_probability``` - The chance of genes inside the individuals to be mutated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49626cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = pyga.GeneticAlgorithm(population, \n",
    "                           num_generations=100, \n",
    "                           num_parents=4, \n",
    "                           mutation_probability=0.5, \n",
    "                           animate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14767024",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga.evolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8bd1c",
   "metadata": {},
   "source": [
    "### Fitness Score Tracking\n",
    "* The maximum fitness value of all sampled in the population is plotted for each generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga.plot_fitness()\n",
    "plt.title(f'Final Fitness Score = {ga.fitness[-1]:.3f}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
